{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \\\n",
    "  langchain \\\n",
    "  langchain-community \\\n",
    "  langchain-core \\\n",
    "  langchain-google-genai \\\n",
    "  langchain-pinecone \\\n",
    "  pinecone-client \\\n",
    "  google-search-results \\\n",
    "  wikipedia \\\n",
    "  sentence-transformers \\\n",
    "  python-dotenv \\\n",
    "  tqdm \\\n",
    "  requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent_bot/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you have two containers for storing items:\n",
      "\n",
      "*   **List:** Like a shopping list you can change. You can add items, remove items, or change the order of items.  It's **mutable** (changeable).  You write it using square brackets: `[apple, banana, cherry]`\n",
      "\n",
      "*   **Tuple:** Like a set of coordinates (x, y). Once you define them, you can't change them. You can't add, remove, or change the order. It's **immutable** (unchangeable). You write it using parentheses: `(10, 20)`\n",
      "\n",
      "**In short:**\n",
      "\n",
      "*   **List:** Changeable, like a shopping list.\n",
      "*   **Tuple:** Unchangeable, like coordinates.\n",
      "\n",
      "**Why use tuples?**\n",
      "\n",
      "*   **Safety:**  Guarantees data won't be accidentally modified.\n",
      "*   **Speed:**  Tuples are generally a bit faster than lists because Python knows they won't change.\n",
      "*   **Keys in Dictionaries:**  Tuples can be used as keys in dictionaries, while lists cannot (because dictionary keys must be immutable).\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Initialize Gemini Flash LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",  # This internally uses Flash for fast responses\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    convert_system_message_to_human=True,\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# Test it\n",
    "response = llm.invoke(\"Explain the difference between Python lists and tuples in simple terms.\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_experimental\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Wikipedia tool\n",
    "wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "# Initialize the Python REPL tool\n",
    "python_repl = PythonREPLTool()\n",
    "\n",
    "# Initialize the SERP API tool\n",
    "search = SerpAPIWrapper(serpapi_api_key=os.getenv(\"SERPAPI_API_KEY\"))\n",
    "\n",
    "# Bundle the tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Python_REPL\",\n",
    "        func=python_repl.run,\n",
    "        description=\"Useful for executing Python code for tasks such as math, logic, and plotting.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Wikipedia\",\n",
    "        func=wiki.run,\n",
    "        description=\"Useful for retrieving factual and historical information from Wikipedia.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Web_Search\",\n",
    "        func=search.run,\n",
    "        description=\"Useful for answering current event or factual queries using the SERP API.\",\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent_bot/lib/python3.10/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "def create_pinecone_retriever_from_pdf(pdf_path: str, index_name=\"doc-chatbot\") -> tuple:\n",
    "    \"\"\"\n",
    "    Ingest a PDF file, upload to Pinecone under a unique namespace, and return a retriever + namespace.\n",
    "    \"\"\"\n",
    "    # Init Pinecone\n",
    "    pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "    # Load and split PDF\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "\n",
    "    # Embedding model\n",
    "    embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Unique namespace\n",
    "    namespace = f\"session-{uuid.uuid4()}\"\n",
    "\n",
    "    # Upload to Pinecone\n",
    "    vectorstore = PineconeVectorStore.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embed_model,\n",
    "        index_name=index_name,\n",
    "        namespace=namespace\n",
    "    )\n",
    "\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    return retriever, namespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/z4x86ysd16l05yl4nzy8wrg80000gn/T/ipykernel_75733/3078288708.py:24: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"/Users/praddy/Documents/CODE/learning_langchain_folder/chatbot-docqa/data/attention.pdf\"  # Youâ€™ll dynamically pass this later via Streamlit\n",
    "retriever, namespace = create_pinecone_retriever_from_pdf(pdf_path)\n",
    "\n",
    "# Wrap as LangChain tool\n",
    "rag_tool = Tool(\n",
    "    name=\"Document_Retrieval\",\n",
    "    func=lambda q: retriever.get_relevant_documents(q),\n",
    "    description=(\n",
    "        \"Use this tool to answer any questions related to the user's uploaded PDF document. \"\n",
    "        \"It contains detailed information the user may reference or ask questions about.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "tools.append(rag_tool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/z4x86ysd16l05yl4nzy8wrg80000gn/T/ipykernel_75733/4247999525.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(query)\n",
      "/opt/anaconda3/envs/agent_bot/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided documents, the main idea discussed is the **attention mechanism**, specifically within the context of the Transformer model architecture. The documents cover:\n",
      "\n",
      "*   The Transformer model architecture using stacked self-attention.\n",
      "*   The encoder and decoder stacks within the Transformer, including multi-head self-attention.\n",
      "*   Visualizations of the attention mechanism, showing how it follows long-distance dependencies and is involved in anaphora resolution.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the main idea discussed in the uploaded document?\"\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Then send that as context to the LLM\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "response = llm.invoke([\n",
    "    HumanMessage(content=f\"Based on the following context, answer the question:\\n\\n{docs}\\n\\nQuestion: {query}\")\n",
    "])\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Initialize the agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,                     # All your tools, including RAG\n",
    "    llm=llm,                         # Gemini Flash\n",
    "    agent=\"conversational-react-description\",\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent_bot/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Hello John from Sydney! It's nice to meet you.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Hello John from Sydney! It's nice to meet you.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent_bot/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Your name is John.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Your name is John.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent_bot/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Document_Retrieval\n",
      "Action Input: What does the document say about self-attention?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[Document(id='ff0348ff-a629-4ddf-9962-62667bd4d569', metadata={'author': '', 'creationdate': '2024-04-10T21:11:43+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'page': 1.0, 'page_label': '2', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '/Users/praddy/Documents/CODE/learning_langchain_folder/chatbot-docqa/data/attention.pdf', 'subject': '', 'title': '', 'total_pages': 15.0, 'trapped': '/False'}, page_content='described in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].'), Document(id='e80973c1-4545-4c9c-bdfb-33be741c8bc8', metadata={'author': '', 'creationdate': '2024-04-10T21:11:43+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'page': 6.0, 'page_label': '7', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '/Users/praddy/Documents/CODE/learning_langchain_folder/chatbot-docqa/data/attention.pdf', 'subject': '', 'title': '', 'total_pages': 15.0, 'trapped': '/False'}, page_content='the approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching'), Document(id='b229130d-db5e-4441-81d7-e8e5dad4b2c1', metadata={'author': '', 'creationdate': '2024-04-10T21:11:43+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'page': 10.0, 'page_label': '11', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '/Users/praddy/Documents/CODE/learning_langchain_folder/chatbot-docqa/data/attention.pdf', 'subject': '', 'title': '', 'total_pages': 15.0, 'trapped': '/False'}, page_content='[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V . Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-'), Document(id='2d16a965-14d2-4451-a866-cb1c599b4b7e', metadata={'author': '', 'creationdate': '2024-04-10T21:11:43+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'page': 5.0, 'page_label': '6', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '/Users/praddy/Documents/CODE/learning_langchain_folder/chatbot-docqa/data/attention.pdf', 'subject': '', 'title': '', 'total_pages': 15.0, 'trapped': '/False'}, page_content='P Epos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-')]\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent_bot/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: The uploaded document describes self-attention (sometimes called intra-attention) as an attention mechanism that relates different positions of a single sequence to compute a representation of the sequence. It has been used successfully in tasks like reading comprehension, abstractive summarization, textual entailment, and learning task-independent sentence representations. The document also mentions that self-attention could yield more interpretable models and that individual attention heads appear to exhibit behavior related to the syntactic and semantic structure of sentences.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: The uploaded document describes self-attention (sometimes called intra-attention) as an attention mechanism that relates different positions of a single sequence to compute a representation of the sequence. It has been used successfully in tasks like reading comprehension, abstractive summarization, textual entailment, and learning task-independent sentence representations. The document also mentions that self-attention could yield more interpretable models and that individual attention heads appear to exhibit behavior related to the syntactic and semantic structure of sentences.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agent_bot/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: You are from Sydney.\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: You are from Sydney.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"You: \")\n",
    "    if query.lower() in {\"exit\", \"quit\"}:\n",
    "        break\n",
    "    response = agent.invoke(query)\n",
    "    print(\"Bot:\", response[\"output\"] if isinstance(response, dict) else response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
